# Databricks Jobs resources
resources:
  jobs:
    model_training_job:
      name: "[${bundle.target}] High-Risk WiFi - Model Training"
      description: Train and register high-risk WiFi detection model

      schedule:
        quartz_cron_expression: "0 0 2 * * ?" # Daily at 2 AM
        timezone_id: "America/Los_Angeles"
        pause_status: UNPAUSED

      tasks:
        - task_key: train_model
          notebook_task:
            notebook_path: ../notebooks/train_model.py
            base_parameters:
              catalog: ${var.catalog}
              schema: ${var.schema}
              model_name: ${var.model_name}
              experiment_path: ${var.experiment_path}

          new_cluster:
            spark_version: 14.3.x-cpu-ml-scala2.12
            node_type_id: ${var.cluster_node_type}
            num_workers: 2
            spark_conf:
              "spark.databricks.delta.optimizeWrite.enabled": "true"
              "spark.databricks.delta.autoCompact.enabled": "true"

          libraries:
            - pypi:
                package: scikit-learn==1.4.0
            - pypi:
                package: mlflow==2.10.0
            - whl: ../dist/*.whl

        - task_key: evaluate_model
          depends_on:
            - task_key: train_model
          notebook_task:
            notebook_path: ../notebooks/evaluate_model.py
            base_parameters:
              catalog: ${var.catalog}
              schema: ${var.schema}
              model_name: ${var.model_name}

          new_cluster:
            spark_version: 14.3.x-cpu-ml-scala2.12
            node_type_id: ${var.cluster_node_type}
            num_workers: 1

          libraries:
            - pypi:
                package: scikit-learn==1.4.0
            - pypi:
                package: mlflow==2.10.0

      email_notifications:
        on_failure:
          - data-science-team@company.com

      max_concurrent_runs: 1
      timeout_seconds: 7200

      permissions:
        - level: CAN_MANAGE
          group_name: data-science-team
        - level: CAN_MANAGE_RUN
          group_name: ml-engineers
        - level: CAN_VIEW
          group_name: analytics-team

    batch_inference_job:
      name: "[${bundle.target}] High-Risk WiFi - Batch Inference"
      description: Run batch inference on new WiFi connection data

      schedule:
        quartz_cron_expression: "0 0 */6 * * ?" # Every 6 hours
        timezone_id: "America/Los_Angeles"
        pause_status: UNPAUSED

      tasks:
        - task_key: batch_inference
          notebook_task:
            notebook_path: ../notebooks/batch_inference.py
            base_parameters:
              catalog: ${var.catalog}
              schema: ${var.schema}
              model_name: ${var.model_name}
              input_table: wifi_connections_raw
              output_table: wifi_risk_scores

          new_cluster:
            spark_version: 14.3.x-cpu-ml-scala2.12
            node_type_id: ${var.cluster_node_type}
            num_workers: 4

          libraries:
            - pypi:
                package: mlflow==2.10.0
            - whl: ../dist/*.whl

      email_notifications:
        on_failure:
          - ml-engineers@company.com

      max_concurrent_runs: 1
      timeout_seconds: 3600

      permissions:
        - level: CAN_MANAGE
          group_name: ml-engineers
        - level: CAN_VIEW
          group_name: analytics-team
